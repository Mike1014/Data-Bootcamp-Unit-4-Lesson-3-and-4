{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'pg11.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and clean the data.\n",
    "moby = gutenberg.raw('melville-moby_dick.txt')\n",
    "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "\n",
    "moby = text_cleaner(moby)\n",
    "caesar = text_cleaner(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse the novels\n",
    "nlp = spacy.load('en')\n",
    "moby_doc = nlp(moby)\n",
    "caesar_doc = nlp(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ETYMOLOGY, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(The, pale, Usher, threadbare, in, coat, ,, he...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(;, I, see, him, now, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0                                     (ETYMOLOGY, .)  Melville\n",
       "1            ((, Supplied, by, a, Late, Consumptive)  Melville\n",
       "2                 (Usher, to, a, Grammar, School, ))  Melville\n",
       "3  (The, pale, Usher, threadbare, in, coat, ,, he...  Melville\n",
       "4                           (;, I, see, him, now, .)  Melville"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group into sentences\n",
    "moby_sents = [[sent, 'Melville'] for sent in moby_doc.sents]\n",
    "caesar_sents = [[sent, 'Shakespeare'] for sent in caesar_doc.sents]\n",
    "\n",
    "# combine them into one data frame\n",
    "sentences = pd.DataFrame(moby_sents + caesar_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the most common words\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "caesarwords = bag_of_words(caesar_doc)\n",
    "\n",
    "# combine the words to create set of unique words\n",
    "common_words = set(mobywords + caesarwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a data frame with features for each word in our common word set.\n",
    "# each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Processing row 9000\n",
      "Processing row 9500\n",
      "Processing row 10000\n",
      "Processing row 10500\n",
      "Processing row 11000\n",
      "Processing row 11500\n",
      "Processing row 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commanders</th>\n",
       "      <th>retentiue</th>\n",
       "      <th>cruell</th>\n",
       "      <th>yes</th>\n",
       "      <th>gold</th>\n",
       "      <th>lusty</th>\n",
       "      <th>winds</th>\n",
       "      <th>careful</th>\n",
       "      <th>write</th>\n",
       "      <th>fierce</th>\n",
       "      <th>...</th>\n",
       "      <th>acquaint</th>\n",
       "      <th>shooke</th>\n",
       "      <th>quite</th>\n",
       "      <th>breathlesse</th>\n",
       "      <th>precise</th>\n",
       "      <th>forge</th>\n",
       "      <th>daye</th>\n",
       "      <th>frequently</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ETYMOLOGY, .)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  commanders retentiue cruell yes gold lusty winds careful write fierce  \\\n",
       "0          0         0      0   0    0     0     0       0     0      0   \n",
       "1          0         0      0   0    0     0     0       0     0      0   \n",
       "2          0         0      0   0    0     0     0       0     0      0   \n",
       "\n",
       "      ...     acquaint shooke quite breathlesse precise forge daye frequently  \\\n",
       "0     ...            0      0     0           0       0     0    0          0   \n",
       "1     ...            0      0     0           0       0     0    0          0   \n",
       "2     ...            0      0     0           0       0     0    0          0   \n",
       "\n",
       "                             text_sentence text_source  \n",
       "0                           (ETYMOLOGY, .)    Melville  \n",
       "1  ((, Supplied, by, a, Late, Consumptive)    Melville  \n",
       "2       (Usher, to, a, Grammar, School, ))    Melville  \n",
       "\n",
       "[3 rows x 3445 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bag of words feature\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the number of punctuation marks in each sentences\n",
    "def number_of_punctuation(sentences):\n",
    "    punct = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []                          # temporary array to hold the tokens\n",
    "        for token in sentences[0][i]:      # list the type of speech for each word in sentence\n",
    "            temp.append(token.pos_)        \n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "        punct.append(len(temp[temp[0] == 'PUNCT']))    # number of punctuation\n",
    "    \n",
    "    return np.array(punct)\n",
    "\n",
    "# create a feature for number of punctuation in a sentence\n",
    "num_punct = number_of_punctuation(sentences)\n",
    "word_counts['Num_Punct'] = num_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the number of verb in each sentences\n",
    "def number_of_verb(sentences):\n",
    "    verbs = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []                          # temporary array to hold the tokens\n",
    "        for token in sentences[0][i]:      # list the type of speech for each word in sentence\n",
    "            temp.append(token.pos_)        \n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "        verbs.append(len(temp[temp[0] == 'VERB']))    # number of verbs\n",
    "    \n",
    "    return np.array(verbs)\n",
    "\n",
    "# create a feature for number of punctuation in a sentence\n",
    "num_verb = number_of_verb(sentences)\n",
    "word_counts['Num_Verb'] = num_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the number of nouns in each sentences\n",
    "def number_of_noun(sentences):\n",
    "    nouns = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []                          # temporary array to hold the tokens\n",
    "        for token in sentences[0][i]:      # list the type of speech for each word in sentence\n",
    "            temp.append(token.pos_)        \n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "        nouns.append(len(temp[temp[0] == 'NOUN']))    # number of nouns\n",
    "    \n",
    "    return np.array(nouns)\n",
    "\n",
    "# create a feature for number of punctuation in a sentence\n",
    "num_noun = number_of_noun(sentences)\n",
    "word_counts['Num_Noun'] = num_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the number of adverbs in each sentences\n",
    "def number_of_adverb(sentences):\n",
    "    adverbs = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []                          # temporary array to hold the tokens\n",
    "        for token in sentences[0][i]:      # list the type of speech for each word in sentence\n",
    "            temp.append(token.pos_)        \n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "        adverbs.append(len(temp[temp[0] == 'ADV']))    # number of punctuation\n",
    "    \n",
    "    return np.array(adverbs)\n",
    "\n",
    "# create a feature for number of punctuation in a sentence\n",
    "num_adv = number_of_adverb(sentences)\n",
    "word_counts['Num_Adv'] = num_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the number of adjectives in each sentences\n",
    "def number_of_adjective(sentences):\n",
    "    adjectives = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []                          # temporary array to hold the tokens\n",
    "        for token in sentences[0][i]:      # list the type of speech for each word in sentence\n",
    "            temp.append(token.pos_)        \n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "        adjectives.append(len(temp[temp[0] == 'ADJ']))    # number of punctuation\n",
    "    \n",
    "    return np.array(adjectives)\n",
    "\n",
    "# create a feature for number of punctuation in a sentence\n",
    "num_adj = number_of_punctuation(sentences)\n",
    "word_counts['Num_Adj'] = num_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of words in a sentence\n",
    "def words_in_sentence(sentences):\n",
    "    words = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        temp = []\n",
    "        for token in sentences[0][i]:\n",
    "            if not token.is_punct:\n",
    "                temp.append(token)\n",
    "        words.append(len(temp))\n",
    "        \n",
    "    return np.array(words)\n",
    "\n",
    "# create a feature for number of words in a sentence\n",
    "num_words = words_in_sentence(sentences)\n",
    "word_counts['Num_Words'] = num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commanders</th>\n",
       "      <th>retentiue</th>\n",
       "      <th>cruell</th>\n",
       "      <th>yes</th>\n",
       "      <th>gold</th>\n",
       "      <th>lusty</th>\n",
       "      <th>winds</th>\n",
       "      <th>careful</th>\n",
       "      <th>write</th>\n",
       "      <th>fierce</th>\n",
       "      <th>...</th>\n",
       "      <th>daye</th>\n",
       "      <th>frequently</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>Num_Punct</th>\n",
       "      <th>Num_Verb</th>\n",
       "      <th>Num_Noun</th>\n",
       "      <th>Num_Adv</th>\n",
       "      <th>Num_Adj</th>\n",
       "      <th>Num_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ETYMOLOGY, .)</td>\n",
       "      <td>Melville</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Melville</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Melville</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  commanders retentiue cruell yes gold lusty winds careful write fierce  \\\n",
       "0          0         0      0   0    0     0     0       0     0      0   \n",
       "1          0         0      0   0    0     0     0       0     0      0   \n",
       "2          0         0      0   0    0     0     0       0     0      0   \n",
       "\n",
       "     ...    daye frequently                            text_sentence  \\\n",
       "0    ...       0          0                           (ETYMOLOGY, .)   \n",
       "1    ...       0          0  ((, Supplied, by, a, Late, Consumptive)   \n",
       "2    ...       0          0       (Usher, to, a, Grammar, School, ))   \n",
       "\n",
       "  text_source Num_Punct Num_Verb Num_Noun Num_Adv Num_Adj Num_Words  \n",
       "0    Melville         1        0        0       0       1         1  \n",
       "1    Melville         1        1        0       0       1         5  \n",
       "2    Melville         1        0        0       0       1         5  \n",
       "\n",
       "[3 rows x 3451 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading in the data, this time in the form of paragraphs\n",
    "moby_para = gutenberg.paras('melville-moby_dick.txt')\n",
    "caesar_para = gutenberg.paras('shakespeare-caesar.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    note: merge the two paragraphs instead of creating two separate feature data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing paragraphs for Moby Dick\n",
    "moby_paragraph = []\n",
    "for paragraph in moby_para:\n",
    "    para = paragraph[0]     # remove the brackets\n",
    "    # removing the double-dash from all words\n",
    "    para = [re.sub(r'--','',word) for word in para]\n",
    "    # forming each paragraph into a string and adding it to the list of strings.\n",
    "    moby_paragraph.append(' '.join(para))\n",
    "    \n",
    "# processing paragraphs for Caesar    \n",
    "caesar_paragraph = []\n",
    "for paragraph in caesar_para:\n",
    "    para = paragraph[0]     # remove the brackets\n",
    "    # removing the double-dash from all words\n",
    "    para = [re.sub(r'--','',word) for word in para]\n",
    "    # Forming each paragraph into a string and adding it to the list of strings.\n",
    "    caesar_paragraph.append(' '.join(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the paragraph into dataframes\n",
    "df_moby = pd.DataFrame(moby_paragraph)\n",
    "df_caesar = pd.DataFrame(np.array(caesar_paragraph))\n",
    "\n",
    "df_moby['text_source'] = pd.Series(['Melville'] * df_moby.shape[0])\n",
    "df_caesar['text_source'] = pd.Series(['Shakespear'] * df_caesar.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Moby Dick by Herman Melville 1851 ]</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETYMOLOGY .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( Supplied by a Late Consumptive Usher to a Gr...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pale Usher  threadbare in coat , heart , b...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" While you take in hand to school others , an...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\" WHALE .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\" WHALE .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KETOS , GREEK .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXTRACTS ( Supplied by a Sub - Sub - Librarian ).</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It will be seen that this mere painstaking bur...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>So fare thee well , poor devil of a Sub - Sub ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EXTRACTS .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\" And God created great whales .\"</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\" Leviathan maketh a path to shine after him ;...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\" Now the Lord had prepared a great fish to sw...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\" There go the ships ; there is that Leviathan...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\" In that day , the Lord with his sore , and g...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\" And what thing soever besides cometh within ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\" The Indian Sea breedeth the most and the big...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\" Scarcely had we proceeded two days on the se...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\" He visited this country also with a view of ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\" And whereas all the other things , whether b...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\" Let us fly , let us fly !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\" This whale ' s liver was two cartloads .\"</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\" The great Leviathan that maketh the seas to ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\" Touching that monstrous bulk of the whale or...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\" The sovereignest thing on earth is parmacett...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\" Very like a whale .\"</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\" Which to secure , no skill of leach ' s art ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\" Immense as whales , the motion of whose vast...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>\" Oh !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>Setting sail to the rising wind , the lonely b...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>Whether fagged by the three days ' running cha...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>\" Heed them not !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>\" But at every bite , sir , the thin blades gr...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>\" They will last long enough !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>At length as the craft was cast to one side , ...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>Almost simultaneously , with a mighty volition...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>\" What breaks in me ?</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>Hearing the tremendous rush of the sea - crash...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>Ahab staggered ; his hand smote his forehead .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>\" The whale !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>\" Oars !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>But as the oarsmen violently forced their boat...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>Meantime , for that one beholding instant , Ta...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>\" The whale , the whale !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>\" Stand not by me , but stand under me , whoev...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>\" Cherries ?</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>From the ship ' s bows , nearly all the seamen...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>\" The ship !</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>Diving beneath the settling ship , the whale r...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>\" I turn my body from the sun .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>The harpoon was darted ; the stricken whale fl...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>For an instant , the tranced boat ' s crew sto...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>But as the last whelmings intermixingly poured...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>Now small fowls flew screaming over the yet ya...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>Epilogue</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>\" AND I ONLY AM ESCAPED ALONE TO TELL THEE \" J...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>The drama ' s done .</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>It so chanced , that after the Parsee ' s disa...</td>\n",
       "      <td>Melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0 text_source\n",
       "0                 [ Moby Dick by Herman Melville 1851 ]    Melville\n",
       "1                                           ETYMOLOGY .    Melville\n",
       "2     ( Supplied by a Late Consumptive Usher to a Gr...    Melville\n",
       "3     The pale Usher  threadbare in coat , heart , b...    Melville\n",
       "4     \" While you take in hand to school others , an...    Melville\n",
       "5                                             \" WHALE .    Melville\n",
       "6                                             \" WHALE .    Melville\n",
       "7                                       KETOS , GREEK .    Melville\n",
       "8     EXTRACTS ( Supplied by a Sub - Sub - Librarian ).    Melville\n",
       "9     It will be seen that this mere painstaking bur...    Melville\n",
       "10    So fare thee well , poor devil of a Sub - Sub ...    Melville\n",
       "11                                           EXTRACTS .    Melville\n",
       "12                    \" And God created great whales .\"    Melville\n",
       "13    \" Leviathan maketh a path to shine after him ;...    Melville\n",
       "14    \" Now the Lord had prepared a great fish to sw...    Melville\n",
       "15    \" There go the ships ; there is that Leviathan...    Melville\n",
       "16    \" In that day , the Lord with his sore , and g...    Melville\n",
       "17    \" And what thing soever besides cometh within ...    Melville\n",
       "18    \" The Indian Sea breedeth the most and the big...    Melville\n",
       "19    \" Scarcely had we proceeded two days on the se...    Melville\n",
       "20    \" He visited this country also with a view of ...    Melville\n",
       "21    \" And whereas all the other things , whether b...    Melville\n",
       "22                          \" Let us fly , let us fly !    Melville\n",
       "23          \" This whale ' s liver was two cartloads .\"    Melville\n",
       "24    \" The great Leviathan that maketh the seas to ...    Melville\n",
       "25    \" Touching that monstrous bulk of the whale or...    Melville\n",
       "26    \" The sovereignest thing on earth is parmacett...    Melville\n",
       "27                               \" Very like a whale .\"    Melville\n",
       "28    \" Which to secure , no skill of leach ' s art ...    Melville\n",
       "29    \" Immense as whales , the motion of whose vast...    Melville\n",
       "...                                                 ...         ...\n",
       "2763                                             \" Oh !    Melville\n",
       "2764  Setting sail to the rising wind , the lonely b...    Melville\n",
       "2765  Whether fagged by the three days ' running cha...    Melville\n",
       "2766                                  \" Heed them not !    Melville\n",
       "2767  \" But at every bite , sir , the thin blades gr...    Melville\n",
       "2768                     \" They will last long enough !    Melville\n",
       "2769  At length as the craft was cast to one side , ...    Melville\n",
       "2770  Almost simultaneously , with a mighty volition...    Melville\n",
       "2771                              \" What breaks in me ?    Melville\n",
       "2772  Hearing the tremendous rush of the sea - crash...    Melville\n",
       "2773     Ahab staggered ; his hand smote his forehead .    Melville\n",
       "2774                                      \" The whale !    Melville\n",
       "2775                                           \" Oars !    Melville\n",
       "2776  But as the oarsmen violently forced their boat...    Melville\n",
       "2777  Meantime , for that one beholding instant , Ta...    Melville\n",
       "2778                          \" The whale , the whale !    Melville\n",
       "2779  \" Stand not by me , but stand under me , whoev...    Melville\n",
       "2780                                       \" Cherries ?    Melville\n",
       "2781  From the ship ' s bows , nearly all the seamen...    Melville\n",
       "2782                                       \" The ship !    Melville\n",
       "2783  Diving beneath the settling ship , the whale r...    Melville\n",
       "2784                    \" I turn my body from the sun .    Melville\n",
       "2785  The harpoon was darted ; the stricken whale fl...    Melville\n",
       "2786  For an instant , the tranced boat ' s crew sto...    Melville\n",
       "2787  But as the last whelmings intermixingly poured...    Melville\n",
       "2788  Now small fowls flew screaming over the yet ya...    Melville\n",
       "2789                                           Epilogue    Melville\n",
       "2790  \" AND I ONLY AM ESCAPED ALONE TO TELL THEE \" J...    Melville\n",
       "2791                               The drama ' s done .    Melville\n",
       "2792  It so chanced , that after the Parsee ' s disa...    Melville\n",
       "\n",
       "[2793 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_moby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate the two data frame into one\n",
    "df_para = pd.concat([df_moby, df_caesar], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    note: tweakin the tfidfvectorizer to increase features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for Moby Dick and Caesar: 3907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# calculate the tf-idf scores\n",
    "vectorizer = TfidfVectorizer(max_df = 0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df = 2, # only use words that appear at least twice\n",
    "                             stop_words ='english', \n",
    "                             lowercase = True, # convert everything to lower case \n",
    "                             use_idf = True,# we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm = u'l2', # applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf = True # adds 1 to all document frequencies, as if an extra document existed that used every word once.  \n",
    "                                             ## prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "# applying the vectorizer\n",
    "para_tfidf = vectorizer.fit_transform(df_para[0])\n",
    "print(\"Number of features for Moby Dick and Caesar: %d\" % para_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn csr matrix into a dataframe\n",
    "df_para_tfidf = pd.DataFrame(para_tfidf.toarray())\n",
    "df_para_tfidf['text_source'] = df_para['text_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set target variable and training/test sets\n",
    "Y_bow = word_counts['text_source']\n",
    "X_bow = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_bow, Y_bow, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9924, 3449)\n",
      "(2482, 3449)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** -- **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split tf-idf vectorizers into training and test sets\n",
    "X = np.array(df_para_tfidf.drop(['text_source'], 1))\n",
    "Y = df_para_tfidf['text_source']\n",
    "X_train_tfidf, X_test_tfidf, Y_train_tfidf, Y_test_tfidf = train_test_split(X, Y, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 90.758667403\n"
     ]
    }
   ],
   "source": [
    "# SVD data reducer, set this to 700 in order to have 90% variance explained\n",
    "svd = TruncatedSVD(700)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "# run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.fit_transform(X_test_tfidf)\n",
    "\n",
    "Y_train_lsa = Y_train_tfidf\n",
    "Y_test_lsa = Y_test_tfidf\n",
    "\n",
    "variance_explained = svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\", total_variance * 100)\n",
    "\n",
    "# for cross-validation\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "Y_lsa = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    note: the accuracy is so high because the text is from two different period of times. If using text from the same author, the results will be lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.990528012898\n",
      "\n",
      "Test set score: 0.925463336019\n",
      "\n",
      "Cross Validation\n",
      " [ 0.90652699  0.9113618   0.93389762  0.92664248  0.91209677]\n"
     ]
    }
   ],
   "source": [
    "# bag of word \n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "train = rfc.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, Y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, Y_test))\n",
    "print('\\nCross Validation\\n', cross_val_score(rfc, X_bow, Y_bow, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.980207351555\n",
      "\n",
      "Test set score: 0.875618374558\n",
      "\n",
      "Cross Validation\n",
      " [ 0.96610169  0.90536723  0.90819209  0.97595474  0.96458924]\n"
     ]
    }
   ],
   "source": [
    "# tf-idf \n",
    "train = rfc.fit(X_train_lsa, Y_train_lsa)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_lsa, Y_train_lsa))\n",
    "print('\\nTest set score:', rfc.score(X_test_lsa, Y_test_lsa))\n",
    "print('\\nCross Validation\\n', cross_val_score(rfc, X_lsa, Y_lsa, cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.971584038694\n",
      "\n",
      "Test set score: 0.953666398066\n",
      "\n",
      "Cross Validation\n",
      " [ 0.92788074  0.94037067  0.94921403  0.93913744  0.93548387]\n"
     ]
    }
   ],
   "source": [
    "# bag of word\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score:', lr.score(X_train, Y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, Y_test))\n",
    "print('\\nCross Validation\\n', cross_val_score(lr, X_bow, Y_bow, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.942035815269\n",
      "\n",
      "Test set score: 0.765371024735\n",
      "\n",
      "Cross Validation\n",
      " [ 0.94774011  0.89548023  0.88418079  0.9688826   0.90651558]\n"
     ]
    }
   ],
   "source": [
    "# tf-idf \n",
    "train = lr.fit(X_train_lsa, Y_train_lsa)\n",
    "\n",
    "print('Training set score:', lr.score(X_train_lsa, Y_train_lsa))\n",
    "print('\\nTest set score:', lr.score(X_test_lsa, Y_test_lsa))\n",
    "print('\\nCross Validation\\n', cross_val_score(lr, X_lsa, Y_lsa, cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.911225312374\n",
      "\n",
      "Test set score: 0.908138597905\n",
      "\n",
      "Cross Validation\n",
      " [ 0.88678485  0.89967768  0.91132608  0.89762193  0.89637097]\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "train = clf.fit(X_train, Y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, Y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, Y_test))\n",
    "print('\\nCross Validation\\n', cross_val_score(clf, X_bow, Y_bow, cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.982092365693\n",
      "\n",
      "Test set score: 0.607067137809\n",
      "\n",
      "Cross Validation\n",
      " [ 0.97457627  0.9420904   0.94350282  0.95756719  0.94334278]\n"
     ]
    }
   ],
   "source": [
    "# tf-idf \n",
    "train = clf.fit(X_train_lsa, Y_train_lsa)\n",
    "\n",
    "print('Training set score:', clf.score(X_train_lsa, Y_train_lsa))\n",
    "print('\\nTest set score:', clf.score(X_test_lsa, Y_test_lsa))\n",
    "print('\\nCross Validation\\n', cross_val_score(clf, X_lsa, Y_lsa, cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Seems like the original selection of training and test set is unaccurate representation of the model. However, after cross-validation, it seems to be working better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
